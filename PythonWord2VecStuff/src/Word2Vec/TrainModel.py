import gensim, logging, numpy

#SentenceIterator is a class that iterates over the training sentences.  
from SentenceIterator import SentenceIterator


#I don't know what this does, but some gensim tutorial told me to include this line.
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)


#I know it is ugly that we use an absolute path (which is tied to my own machine) rather than a relative one,
#but this was necessary because I have not figured out how to include both java and python
#code in the same eclipse project in a way that would 1) make them both work, and 2) 
#would make them both handleable with egit.
#Hard-coded absolute paths allow the separate projects to communicate with each other via files 
#they write without demanding a lot of command line arguments from the user.

#This is the input file containing the training sentences, one per line.  It is generated by the java program gov.ornl.stucco.SriteTrainingInstances.
preprocessedfile = '/Users/p5r/stuccovm/preprocesseddata/aliassubstitutedentitynamesprocesseddocuments'

#These are the files this program can produce.  
#This file is the actual word2vec model.  But since we don't use the model for anything, I commented out everything having to do with writing it.
#word2vecmodelfile = '/Users/p5r/stuccovm/models/securityword2vecmodel'

#This file is where we write our word vectors, which we do actually use.
wordvectorsfile = '/Users/p5r/stuccovm/models/wordvectors'


#Some parameters.  I set them to what I thought were reasonable defaults, or values we discussed.
hiddenlayersize = 100
windowsize = 1 #maximum distance between words looked at during training.
skipgramorbow = 1 #1 for skip gram.  0 for continuous bag of words.
wordoccurrencethreshold = 1 #If a word occurs at least this number of times in our dataset, include it in our vocabulary.


#Get the corpus sentences to train on.  sentences is actually an iterator, so we do not have to worry about trying to store it in its entirety in memory.
sentences = SentenceIterator(preprocessedfile) # a memory-friendly iterator


#Train the model.
model = gensim.models.Word2Vec(sentences, size=hiddenlayersize, workers=4, window=windowsize, sg=skipgramorbow, min_count=wordoccurrencethreshold, sorted_vocab=1)    


#Write the word vectors to a file.  
#This is the only result we actually 
#The gensim api does not specify if model[k] is k's in or out vector.
wordvectorsfilestream = open(wordvectorsfile, 'w')
for (k, v) in model.vocab.iteritems():
    #print(k + "\t" + model[k])
    wordvectorsfilestream.write(k)
    numpyarray = model[k]
    for value in numpy.nditer(numpyarray):
        wordvectorsfilestream.write(" " + str(value))
    wordvectorsfilestream.write("\n")
wordvectorsfilestream.close()
    

#Save the word2vec model too.
#Only, since we never actually use the model, I just commented it out, and we will throw it away.
#model.save(word2vecmodelfile)




